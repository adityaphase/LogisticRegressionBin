{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by defining a sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import optimize as op\n",
    "import numpy as np\n",
    "from math import exp\n",
    "\n",
    "def Sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where z is the linear regression hypothesis given as k0 + k1 * x1 + k2 * x2. We shall be retaining k0 = 1 as a standard constant.Lets now import data and modify it to carter our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/Users/adityaphase/Desktop/ex2data2.csv\", usecols=['X1', 'X2', 'Y1'])\n",
    "x = dataset.iloc[:, [0, 1]]\n",
    "y = dataset.iloc[:, [2]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sx = StandardScaler()\n",
    "xtrain = sx.fit_transform(xtrain)\n",
    "xtest = sx.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall use train_test_split method to split our dataset as 75% training data and rest as test data. For larger datasets it would be a better idea to split it as 50 - 50%. The purpose of standard scaler is to run feature scaling on our input data which would help to normalise data within a particular range. Now lets convert these matrices into numpy arrays to make them easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(xtrain)\n",
    "y = np.asarray(ytrain)\n",
    "X1 = np.asarray(xtest)\n",
    "y1 = np.asarray(ytest)\n",
    "y2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empty list y2 shall be used later. Lets now extract the shape of array X and initialise the initial theta as a array of 0. The size of this array will be equal to number of columns in x ( as our hypothesis is k0 + k1 * x1 + k2 * x2 )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m , n = X.shape\n",
    "initialTheta = np.zeros(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define a cost function. Cost function minimization is crucial for finding accurate hypothesis parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta,x,y):\n",
    "    m,n = x.shape \n",
    "    theta = theta.reshape((n,1))\n",
    "    y = y.reshape((m,1))\n",
    "    n1 = (np.log(Sigmoid(x.dot(theta)))).reshape((m, 1))\n",
    "    n2 = (np.log(1-Sigmoid(x.dot(theta)))).reshape((m,1))\n",
    "    func = y * n1 + (1 - y) * n2\n",
    "    J = -((np.sum(func))/m)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have divided the two terms y(log(h(x))) and the term (1 - y)log(1 - h(x)). Doing a dot product on these vectors and subtracting them yields the final cost function. Now our main purpose is to minimise the cost function since cost function tells us how wrong is our model in predicting the relation between x and y and thus its no brainer to minimise it to achieve max accuracy. We shall be minimising the cost function using gradient descent to achieve a minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(theta,x,y):\n",
    "    m , n = x.shape\n",
    "    theta = theta.reshape((n,1))\n",
    "    y = y.reshape((m,1))\n",
    "    n1 = Sigmoid(x.dot(theta))\n",
    "    grad = ((x.T).dot(n1-y))/m\n",
    "    return grad.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we define a gradientDescent function to minimise the cost. Gradient descent is in layman terms the partial derivative of the cost function coming out as sum{ (h(Xi) - Yi)Xi ) }.The flatten method is used to convert a multidimensional array to a single 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = op.minimize(fun = cost, x0 = initialTheta, args = (X, y), method = 'TNC', jac = gradientDescent)\n",
    "modelledTheta = Result.x\n",
    "print(modelledTheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the secret sauce for predicting the accurate values of theta. The minimise method is a powerful method which Newtons Conjugate Gradient to predict theta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X1, y1, modelledTheta):\n",
    "    c = 0\n",
    "    for i in range(0, len(X1)):\n",
    "        z = 1 + modelledTheta[0]*X1[i, 0] + modelledTheta[1]*X1[i, 1]\n",
    "        y2.append(round(1 / (1 + exp(-z))))\n",
    "    for i in range(0, len(y1)):\n",
    "        if y2[i] == y1[i]:\n",
    "            c += 1\n",
    "    print(\"Accuracy: \", (c / len(X1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to use our predicted theta to test on our test dataset. We shall also find the accuracy of our model. Running our model on training data yields a accuracy of 92 % which is not too shabby."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
